{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muratkoc503/deneme/blob/master/SegFormer_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUSTOM DATASET TRAIN FOR SEMANTIC SEGMENTATION WITH SEGNET"
      ],
      "metadata": {
        "id": "8OZfp88D_dzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pytorch re-install for SegNet"
      ],
      "metadata": {
        "id": "zAMOJyxY_2CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SegNet için pytorch'un farklı sürümü kullanılıyor. Bu yüzden eğitim işlemi bilgisayarın kendi işlemcisi kullanılarak yapılıyorsa(Colab değil anlamında), conda ile yeni environment kur ve orada yap."
      ],
      "metadata": {
        "id": "99CYwwbPAS1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning transformers datasets roboflow==0.2.7"
      ],
      "metadata": {
        "id": "htiU7EK90pCN",
        "outputId": "e862cfaf-ab09-43c2-ffdf-c0d74bc315ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (1.7.7)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: roboflow==0.2.7 in /usr/local/lib/python3.7/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (1.21.6)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (2.4.7)\n",
            "Requirement already satisfied: Pillow==8.4.0 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (8.4.0)\n",
            "Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver==1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (1.3.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (4.64.1)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (1.26.6)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (3.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (2.28.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (6.0)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (4.0.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (0.9.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (2.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (3.2.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.1.2.30 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (4.1.2.30)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (0.10.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (from roboflow==0.2.7) (0.21.0)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.1+cu113)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2022.8.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.10.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.49.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roboflow connection and Dataset Download with Roboflow"
      ],
      "metadata": {
        "id": "bu1R2B0SAD6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![datas.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOwAAADjCAYAAACGhfjBAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AACAASURBVHic7d15XE7538fxV5vINllmMihlC5E9yRhFJfvOPZQxkWVsM3dkGyXbne4mYxvbEEbNYjARWWNGP8tgSMOYErIUMyNjidJy/9F0bpeWK3TRyef5ePR4dJ3le77n6vp0tuu8j152dnY2QghV0H/dHRBCFJ0UrBAqIgUrhIpIwQqhIlKwQqiIFKwQKiIFK4SKGOqq4SNHjhAdHZ1nuLm5Of/1X/+lq8UKUarppGATExNZt25dvuMuXrxIamoqnp6euli0EKWaTgo2NTW10PHR0dH5bn1zNWzYEB8fn+LulhCq90qPYatWrVqk6S5evMjvv/+u494IoT6vrGAdHBwIDAzEwcHhVS1SiFLnlRSsg4ODcszq6ekpRSvEC9J5wT5drLmkaIV4MTot2Nq1a9OhQwcSExM1hicmJtKhQwdq166ty8ULUerotGCvXbtGQEAAYWFhGsPDwsIICAjg2rVrL9x2SEgIFy9eBHLOSi9ZsoR79+69VH+FKOlU+02n0NBQfv31VwBu377N119/zc2bN19zr4TQLZ1900nX9u7dq/xep04dTpw48Rp7I8Sr8UoKNjExkYCAAI3XQojnp5OCNTEx0Xj96NEj5XjzRdsQQoCerkLYCvryf1E4OzvTsmXLYu6REOqns4IVQhQ/1Z4lFuJNJAUrhIpIwQqhIlKwQqiIFKwQKiIFK4SKSMEKoSJSsEKoiGoLtkuXLlhZWWFlZUXDhg1xdnYmNDS0yPOPHj0aX19fAM6fP4+VlRUpKSm66u5LuXPnDitXrsTR0THPuNOnT9OvXz9sbGxwdXVlz549r6GH4lVRdS6xp6cnQ4YM4cmTJxw7dozZs2dTq1YtOnbsWCztlwT+/v6EhoZSsWJF7t69qzEuKSmJ4cOHM2rUKP73f/+Xo0ePMmHCBHbt2kW9evVeU4+FLqk6l7hq1arUrVsXAGtra/bt28fhw4dLVcFWqlSJ0NBQ7t+/z8iRIzXG7d+/n7fffpuJEycCYGVlxTfffMPhw4elYEupUpVLbGBgwKNHj5TXUVFRBAUFER8fT61atfD29qZr165Famv16tVs2LCBO3fu0Lp1a/z9/bG0tARy1m/u3Lns3r2b7Oxsunbtiq+vLyYmJqSmpmJjY8PChQsJCQkhMTGR1q1bExwcTJUqVQDYuXMnixcvJikpiYYNGzJ79myaN2+ebz8mT54MwOHDh/OMGzRoEP3799cYZmhoqPX9F+pVIo9hnzeXOCsri3379nHs2DF69uwJQHx8PF5eXri7uxMVFcXw4cOZNGkSSUlJWtv76quvWLlyJX5+foSHh1OlShVGjBjBkydPAJg0aRKxsbFs2LCBkJAQYmJimDlzpkYbq1atYvbs2YSEhJCQkMCqVasASEhI4JNPPmHChAns3r2bpk2b4unpSVpaWpHXN5exsbFyG2JWVha7d+8mLi5OeQ9E6aPaxAmAoKAgFi9eTGZmJpmZmQwcOBB7e3sAqlevzvbt22nSpAkA7u7uBAYGEhMTQ40aNQpsMzs7m7Vr1zJhwgScnZ0BWLRoEQ4ODuzcuZPmzZtz4MABIiIiaNSoEQCBgYH07t0bb29vTE1NAfD19VX60rNnT2JiYgC4evUq+vr6ODk5UbFiRXx8fKhbty6PHz/G2Nj4hd6H+fPns3HjRp48ecLcuXOpU6fOC7UjSj7DzMxMNm/eXOCWp0aNGgwdOhQDA4NX3DXtPvzwQ4YMGUJWVhaXLl3C19eX1atX4+XlReXKlTl58iS+vr5cvnyZjIwMHj58SHp6eqFtpqSkcOvWLVq3bq0MMzY2plmzZvzxxx/KVi23WAFsbGwoW7YscXFxtG3bFsg59syVu6sM0L59e1q1aoWjoyOurq506dKFYcOGoa+vj4eHhxJ1M2TIEPz8/Ir0PowbN45BgwZx/PhxFi5ciLW1Na1atSrSvEJdDA0MDOjduzcBAQEkJydrjDQzM2PMmDElslhB86RT/fr1uXTpEqGhoXh5eREbG8vEiRP5/PPPcXJywsjIqEgf4jJlygDkWefMzEzS09MpU6YM+vqaRxLZ2dlkZWVp/WcAOcUfGhrK6dOniYqK4rPPPqNmzZps3ryZRYsWKbvGFStWLNJ7AGBqaoqpqSn169fnxIkThIaGSsGWUvoAlStXxsfHR+PZN2ZmZvj4+FC5cuXX1rnnlZ2drRTa8ePHsbS0xNXVFSMjIzIyMopUUBUqVMDMzExJZARIS0sjNjYWa2tr6tevz4MHD4iPj1fGx8bGkpaWhrW1tdb2o6Ki+O6772jZsiX//d//zY8//sgvv/zCmTNnMDMzw8LCAgsLC+UEVWHWrFmjnJTKpa+vr/zTEaWPcgybW7S5YWlqKNaUlBSuXr1KVlYWFy5cYP369QwePBjISVK8ePEiW7duxcLCgrVr1xZplxhgzJgxBAcHKwW0fPlyjI2N6d69OyYmJnTt2hVvb2/8/f3Jzs5mxowZuLi4YG5urvUMbXp6Or6+vpQvX145HjY0NHyhUPWWLVuyaNEi2rZty3vvvUdsbCx79+7lyy+/fO62hDponHSqVq2acjmlpBcr5Gxh1qxZg76+PjVq1GDIkCFMmjQJgM6dOzN69Gjmz5+PsbEx7u7upKenc//+fa3turu7c+/ePWbOnMm9e/do06YNYWFhyhnZgIAA5syZw9ChQzE0NMTNzY1Zs2YVqc+urq5MmTKFgIAAbt++TZ06dVi+fDnvvPPOc69/q1at+OKLL1i6dCnz5s2jZs2a+Pv78/777z93W0IddJLp9Pvvv7No0aKXamPq1KlF2sUU4k1SIq/DCiHyp5OCLY5MYcklFiIvySUWQkUkl1gIFZFjWCFURApWCBWRghVCRaRghVARKVghVEQKVggVkYIVQkWkYIVQESlYIVRENZlOus45njVrFnfu3GHFihUv3daOHTvw8/Pj1KlTL92WEE9TRcG+qpxjIUo6nX6XODMzs1jyoF72/lptOce2trYaN7bHxsZiYmLCzz//zIIFC7h27RpNmjRh7ty5NGjQAMh5vIevry/nz5/n7bff5uOPP2bAgAGMHj2affv2KW2tXbsWJyenF+67EE/T6THs5s2b+eeff3S5iCLRlnN89OhRBg0ahIuLi1KsFy5cYOzYsYwePZqIiAhsbGzw9PRUsolHjRpFs2bNiIyMZNy4cUyfPp2zZ8+yZMkSAgMDMTU1JTY2VtIfRLHSacEmJSUREBBQIoq2MCYmJhgaGqKvr6/ch7tu3Tr69OlDnz59sLCwYMaMGfzzzz+cPHmS1NRUkpOT6dixI7Vr12bgwIEEBgZSrlw5jI2NlRA0ExOTEps4KdRJ58ewycnJBAQEqCLU7Wnnz58nPj6e7du3K8MePXrEjRs3sLe3x8vLi7Fjx9KpUyecnJzo1q2b3HQvdO6VXNZJTk5m3rx5/PXXX69iccVmxIgRREREKD8HDx5Uns3j4+PD7t27adWqFZs3b8bJyYnExMTX3GNR2sl12H/p6elpvK5Xrx7x8fFKTrCFhQXVqlWjQoUKxMfHExQUhLm5OZ6enmzdupXKlSsTHh6eb1tCFJdXUrBVq1bFx8eHatWqvYrFvZC33nqLCxcucO7cOTIyMhg5ciSHDh1i6dKlXL16lT179tCxY0eSk5OpUKECa9euZfHixVy7do3o6GiSk5OxsrICcpL47969S3R0dJ5nugrxMnResGZmZsyaNatEFytA//790dPTY+jQody/f5+mTZuybNkyduzYgbOzM4GBgfj5+WFmZoaZmRlr167l4MGDODs74+Pjg5eXF926dQPAzs5OOc6VL0+I4qTT67AbN26kd+/eL32ySXKOhcih07PEJfWpd0KolU53iYurWCXnWIgcqok5lZxjIVRUsEIIuQ4rhKpIwQqhIlKwQqiIFKwQKiIFK4SKSMEKoSJSsEKoiBSsECoiBVtMLl26RPv27bl169br7oooxVQRcwolP5fYzMwMT09PqlSp8tJ9EaIgqijY151LnJWVhb5+4Tsj5cuXl2xkoXOSS0z+ucSLFy/m7NmzlC9fnujoaGJiYrh+/Trz5s3j+PHjVKpUicGDB/PJJ58AOaFtPXr04NSpUxgbG2NjY8PChQsJCQkhMTGR1q1bExwcLFtg8VIkl5j8c4kBTp06RadOnfjxxx8xMDDAw8ODmjVrsm/fPoKDg1m/fj07d+4ssN1Vq1Yxe/ZsQkJCSEhIYNWqVcW+buLNotNd4txc4pIecZpfLjHkRL14eHgAOXsLK1eupF69epQrV46aNWvSrl07Tp8+TY8ePfJt19fXF3t7ewB69uxJTEyM7ldGlGo6P0ucm0tcEra0z8vIyEj53cDAgLJlyzJ58mTs7e1p1qwZhw4dIj09vcD5K1WqpPxuYmJCamqqTvsrSj/JJS6itLQ03N3dsba2Zu/evcTExNClS5fX3S3xhpHrsP/SliUcFxfH7du3GTlyJBUrVgRyngQgxKskucT/ejaX+FnvvvsuZcqUYdmyZcTExBAUFMRPP/1U6C6xEMVNcon/9Wwu8bOqVKlCcHAwkZGReHh4kJSUxMiRI5Wn2QnxKkgusRAqIrnEQqiI5BILoSKqiTmVXGIhVFSwQgi5DiuEqkjBCqEiUrBCqIgUrBAqIgUrhIpIwQqhIlKwQqiIFKwQKiIF+5JGjx6Nr68voD2beMuWLbRv3/5Vdk+UMqqIOQXd5xIXB8kmFrqmioJ93bnERSXZxELXdFqwxZVLrC28LDo6utAbA7TlEk+dOpWHDx+yfPlyICc43M7OjtmzZ9OzZ0+ioqIICgoiPj6eWrVq4e3tTdeuXfO083Q2sampKUlJSXh7e/Prr7/SoEEDuQFBvDTJJQa6d+/O4cOHlbiXM2fO8ODBA5ycnIiPj8fLywt3d3eioqIYPnw4kyZNIikpSetyvb29uX//Pps2bcLb25sDBw4U2zqJN5NOCzY3l7gkFG1hOnTogLGxMf/5z38A2L9/Px07dqR8+fJUr16d7du3M3jwYGrUqIG7uzvGxsZaM4avXLnC0aNHWbBgAa1ataJDhw6MHTv2VayOKMUkl5icG+2dnZ3Zu3cvkFOw3bp1A6By5cokJyczYMAAWrVqha2tLQ8fPtQavnblyhUMDQ1p0qSJMszQUBWnDEQJJrnE/+revTsHDhzg8uXLJCYm0rlzZyDnOTsTJ05k1KhRHDt2jLNnz/LWW28VqU0jIyOt8alCPA+5Dvuv9u3bk5GRQWBgIO+99x4VKlQA4Pjx41haWuLq6oqRkREZGRlFija1srLi0aNHJCYm6rrr4g0iucT/MjAwwNXVlcjISNzc3JThderU4eLFi2zdupVTp04xYcKEIu0Sm5ub0759e/z9/fn777+5du0aGzZs0PVqiFJOcomf0qNHDwwNDTUewdG5c2dGjx7N/PnzmTBhAs2aNcPR0THf7OJnBQYG8ujRIzp06ICXlxdt27bVZffFG0ByiYVQEcklFkJFJJdYCBVRTcyp5BILoaKCFULIdVghVEUKVggVkYIVQkWkYIVQESlYIVREClYIFZGCFUJFVHdHdWJiIo8ePSpwfMOGDV9hb4R4tVRVsEeOHCkwPTGXg4PDCyUXdunShYSEBCDnxvM6derw4YcfKhGqO3bsYNKkSXnmq1atGidOnNAYNnbsWK5du8bOnTs1hv/555/Y2dkBoKenx9tvv02XLl349NNPMTU11ejLjRs3OHHiBBUrVsyzTDc3Ny5evMiZM2eoVKmSRt+fNnfuXIYOHap13adMmUJGRgbBwcFapxWvl6oK9tdffy1wXMOGDalWrZry9cUXKVpPT0+GDBnCkydPOHr0KH5+fpQtW5a+ffsCOYW8a9cujXmejX15+PAhhw4d4smTJ1y6dIm6devmWc6SJUto1KgRt27dYtWqVfTr148dO3YoN80DpKWlsXv3bgYNGqQx74ULF7h48WKBfX9a9erVn+8NKIIdO3bg5+fHqVOnir3tZ82aNYs7d+6wYsWKYulLly5d8PDwwMPDozi7+UqpqmC1xZ3mFumLFm3VqlWVArO2tiYhIYHNmzcrBaunp5dvAT5tz5491K5dm5o1a7Jjxw4mT56cZ5qaNWtSt25d6tatS9u2bXFzc2P58uUaUazm5uZs27YtT8Fu27YNc3PzPEkWT/ddlF6l7qSTp6cnDg4OREdH89VXX71UW9bW1ly/fv255tmxYwddu3bFzc2N8PBwrdMbGhri7u6eZ9pu3bpx4sQJbty4oQzLyspix44ddO/e/bn69Kxjx47h7OxM06ZNGTt2LHfu3NEYHxUVRY8ePbC2tqZLly5ERkYCOY8lmTRpEikpKVhZWXHw4MFCpwfIzs4mKCiIdu3aYWtry9ixY7l9+7YyPjExEQ8PD2xsbHBxcVHmtbW1JTQ0lMjISKysrPL8s86vLxERETRq1Ej5m509e5a6devyzTffYGVlRUJCAn5+fvTq1eul3r/XqdQVLGgWbWho6Au3c+PGDY1jS21SUlI4cuQIrq6uODs7c+3aNWJjY7XOV7duXZKSkjQ+lDVr1qRZs2Zs375dGRYdHc39+/dxdHR8vhV5yoMHDxgzZgy2traEhYXRuXNnJd4VKDSHecmSJQQGBmJqakpsbCzvv/++1tzm7777jm+//ZYVK1awZcsW7ty5w7Rp04CcPaahQ4fSuHFjIiIilCKMi4vj6NGjDBo0CBcXF2JjY/PcHplfX7p3746dnZ0SdjB37lx69erFoEGDiI2NxdLSkpkzZ/Ldd9+98Pv3upWagv3rr7/48ccflZ9q1apRrlw5rl279txtZWVlcfToUTZv3kz//v2V4enp6VhbW2v8HDlyRBm/a9cu3n33XZo0aYKpqSl2dnbs2LFD6/JyUxjv3bunsax+/fqxbds2Zdj27dtxc3PL9z7joKAgjX49ezyba+fOnRgYGLBw4UJsbGwYMGAArq6uyvjCcpiNjY0pU6YMkHN/sYGBgdbc5oSEBGrXrk2LFi2oX78+//M//6NkZu3atYuyZcsybdo0LCws6N+/Px06dGDnzp2YmJhgaGiIvr5+vvcy59cXgDlz5rBv3z78/f2Ji4tj5syZSht6enoYGRlRtmxZrX+TkkpVx7CF+fvvv/nxxx9fqo2goCAWL15MZmYmmZmZfPTRR3z00UfKeCMjIyIiIjTmqVGjhvJ77u5wLjc3N1asWMG0adMKjTv9+++/AahUqZIyLD09nT59+jB37lxiYmKoV68ee/bsYc2aNTx58iRPGx9++KFGkRb0obxy5QqNGjXCyMhIY70yMjKAnBzmkydP4uvry+XLl8nIyCg0dE7b9EOGDCEiIgIXFxecnZ3p1q0bAwcOBHJOoF25cgUbGxulvbS0tOfaq3mWhYUFY8aM4YsvvmDOnDmqyBJ7HqWmYItD7oc+LS2NYcOGUb9+ffT1/38npLCTTsnJyfzyyy+cOnVKSUfMzs7myZMnnDx5kjZt2hS43Pj4eN5++22NLUl2djampqY4Ojqybds2bG1tqVy5MnZ2dnkuI0HRTzrp6ekpW6b85OYwf/755zg5OWFkZESrVq1eeHpLS0uioqL46aefOHToEEOGDMHDw4OpU6cC0KpVKwICAjTaLF++vNb1KExuQN6DBw9eqp2SqNTsEheH3A9948aNmTBhAkFBQTx8+LBI80ZERFCrVi0iIyOJiIggIiKCXbt20a5du0J3i9PT09mwYQM9evTId3zuJZ/vv/+ePn36aPwDeRGWlpbExcXxdG7B079ry2F+dk9B2/QbNmzg5MmTdO7cmblz5xIQEMDatWvJzs6mbt26xMfH884772BhYYGFhQXVq1dXtoraQtjzG3/+/Hk2bdrErFmzWLZsmcZJw9IQ6i4FWwB3d3cqVKigcQ0wOzubq1evavzkXl4JDw/Hzc1NuVyT+9OrVy927dpFZmam0k5ycjJXrlzh559/xsPDAz09PSZOnJhvP5ycnJRj6n79+hXY35SUlDx9y308SkhIiHLttnv37jx48IClS5fy8OFDTpw4wf79+5V2tOUwm5qacvfuXaKjo7l7967W6a9cucLMmTM5deoUiYmJHDp0CEtLS/T09OjTpw9GRkZ8+umn/PHHH5w5c4a+ffuye/duIOfY/sKFC5w7d46MjAxSU1NZsmSJcqz/bF+ysrKYNWsWAwYM4KOPPqJDhw74+fkp6/bWW29x7NgxLl26VLQPQQkkBVsAQ0NDpk2bxrp165RLK0+ePMHR0VHjp3PnziQmJnLu3DmNAPJcrq6u/PPPPxp5VB9//DGdO3dm6tSp1KtXj61bt2ocvz7NyMiI7t2706xZs0J3edesWZOnb5s2bQIgNDRU+dJJ+fLl+fLLLwkPD8fOzo6lS5dib2+vtKMth9nOzg57e3u8vLw4deqU1umnTp2Kg4MDXl5edOvWjZs3b7Js2TIg52RRSEgId+/epVevXowePRpXV1dcXFwA6N+/P3p6egwdOpT79+9z+/Ztvv76a27evJlvX8LCwoiLi+PTTz8FYMaMGfz888/s2bMHgJEjR3Ls2DFld1yNVJXpFBAQkO+3fAqj7dmwQqiJbGGFUBEpWCFURApWCBVRVcE6ODg89zzOzs466IkQr4eqTjpBzpfFtd21k8vExARzc3Md90iIV0d1BSvEm0xVu8RCvOmkYIVQESlYIVREClYIFZGCFUJFVHc/rOQSizeZqgpWcolzFHcusTa9evWiW7dujBkz5oXbuHTpEoGBgVy+fJlq1aphbW3N+PHjXypd4k2kqoKVXOLXn0v8IrKzsxk9ejQNGzZkzpw5XL9+nalTpzJ48GCdFWzuP8fIyEgaNGigdXptGcglhaoKVnKJiz+XOCsr66VTLLS5desWCQkJrFmzBktLS/7880+dLq80K3UnnSSXuHAHDx7ExsaGefPmYWtry88//wzA6tWrcXBwoFGjRri7u3P58mWN+a5evcqgQYOwtrbGzc2Ns2fPaowvaP779+8rCYq3b99W4k+flpqayvTp02nevDm2trb4+Pgo/5znzJnD+PHjlWk3b95M+/btldexsbHUr19fI3Fy3bp1yqFH165dWbBgQYGZxUePHtWagVySlLqCBckl1iY1NZXU1FTCwsJo3bo1X331FStXrsTPz4/w8HCqVKnCiBEjNNIZIyMj+eijj/j+++8xNzfn448/VmJvCpv/zJkzBAUFAeDv78/GjRvz9GfSpEnExsayYcMGQkJCiImJYebMmUDOOYnjx48r00ZFRZGcnMyFCxcA+OWXX2jatKlGYoeHhweHDh0CcqJhp0yZUmBmsb29vdYM5JKk1BSs5BIXLZcYcrbqc+fOpXHjxpiYmLB27VomTJiAs7Mz9evXZ9GiRTx48EDjpNnw4cPp2rUrTZs2JSAggL/++ovo6Giys7MLnf+9995j6dKlQE621LPpH5cvX+bAgQMsWrQIW1tbWrRoQWBgIOHh4dy4cQN7e3vu3r3LpUuXSE9P58SJE7i4uBAVFQXkFOyzd3EZGhpSrlw5ICfuNTfSNb/MYkBrBnJJoqpj2MJILnHRcokB9PX1laJPSUnh1q1btG7dWhlvbGxMs2bN+OOPP/Jt76233qJWrVpcu3atyPMX5MKFC5iYmNCoUSNlmI2NDWXLliUuLo5OnTpha2vL8ePHuXnzJg0bNqRv376sXbuWcePGcfLkSYYPH651OVA6MotLTcEWhzchl/hZuRnFz261MzMzCwwPzx2fnZ39wvM/vfxnT3plZ2eTlZWlzP/ee+9x/PhxEhIScHR05L333uOTTz7h119/5eHDh7Rs2VL7iv5L7ZnFpWaXuDi8CbnEz6pQoQJmZmYal8zS0tKIjY3F2tpaGfb48WPl95SUFG7evImFhUWR5y9I/fr1efDgAfHx8cqw2NhY0tLSlPkdHBw4ceIEhw4dolOnTpiYmNC6dWuCgoKws7PTeIpBrtKaWSwFW4DSmkucnzFjxhAcHMyBAweIj49n2rRpGBsba5yN3rBhA7t27eLcuXNMmzYNMzMz5WxtUeYviIWFBV27dsXb25uYmBjOnj3LtGnTcHFxUcIHWrRowYMHD3j48CGNGzdW3pf//Oc/yvHrs5nFlSpVQl9fn4MHD5KcnFykzOKnM5BLKtklLkBuLvGkSZP44IMPgP/PJX6agYEBBw4c4Ny5c/j7++dpx9XVlc8++4zo6GjlOO3jjz9WvunUuXNnVqxYoTWX+Ny5c1pzidesWaMx7NNPP2X8+PGEhoZStmzZAr+26e7uzr1795g5cyb37t2jTZs2hIWFaeyiDxw4kPXr1yvH08uXL1d2g4syf2ECAgKYM2cOQ4cOxdDQEDc3N2bNmqWMNzAwoF27dlStWlUZ5uTkhL+/v1KwuZnFLi4uVKpUiTJlyuDl5cWyZcv4559/qFWrFnFxccp7NGPGDFxcXNizZw+urq7079+fiIgIhg4dyuHDh0vsN7BUlTghucTq9PjxYy5cuEDTpk0xNDQkIyODc+fO0ahRI1U/Se51kC2s0LmyZcvSokUL5bWhoaHGa1F0cgwrhIpIwQqhIqoqWMklFm86VZ10AsklFm821RWsEG8yVe0SC/Gmk4IVQkWkYIVQESlYIVREClYIFZGCFUJFVFuwtra27N69G4Affvih0FvPnnbw4MEi3adZVJcuXaJ9+/bcunWr2NrMz9PrK95cOvvy/5EjR5S40aeZm5sr4dzFpUWLFsV2A/KOHTvw8/Pj1KlTRZrezMwMT09PqlSpUizLF6IwOinYxMTEAhP6L168SGpq6gsFfRfEysoKKyurYmvveZQvX75Y10WIwmjsEj+divAytH11MDo6Wgk4y+8nICDguZa3bt06XF1dlddHjx6lS5cuWFtbM2LECKZMmZIn0SEsLAx7e3uaN2/O7NmzlXT6SZMmkZKSgpWVFQcPHiQ1NRUr1EfG5gAAClVJREFUKyu+/fZb3NzcaNKkCcOHD+fOnTtATuyIlZUVKSkpWqctat+KorAc4fT0dHx8fLCxscHe3p6NGzdiZWXFpUuXgJx0iokTJ2Jra4udnR3z588vtr+90C2Ngt28ebMSK/I6Xbx4kd9///2F5r1//z5jxoyhZcuWbNmyhe7du+dJOkxPT2ffvn2sWbOGefPmERYWxqFDh1iyZAmBgYGYmpoSGxvL+++/r8yzatUqZs+eTUhICAkJCaxatarAPhQ0bVH6VhTacoS//PJL9u/fT1BQEKtXr1YiQXP5+/vz559/snXrVr744gvCw8NfOnRdvBoau8RJSUkEBATg4+ND5cqVX1efXsrOnTspU6YM8+fPx8jICBsbG44fP05aWpoyjYGBAUuXLqV8+fLY2Niwfv16fvvtNxwdHZUUwGfjTXx9fbG3twegZ8+eSpp9fgqatih90+bZHGCARYsW4eDgwM6dO+nbty9hYWGMHz9e2euYO3cuHTt2VNpISEjAwcFByZ1avHhxvtGpouTJc5Y4OTmZgICAErGlfRFXr16lUaNGGkl6z0ZwGhgYUL58eeV1uXLltO7GP525ZGJiUuj0BU1blL5poy0H+NGjR9y+fRtbW1tl/LMP7Bo3bhwbN25kyJAhrF69GktLS42CFiVXvpd1kpOTmTdvHn/99der7s9L09fX1/nDnV5UcfRNWw6wvr4+enp6hZ41d3V15ciRIwwYMIDTp0/j5OTE3r17X6pf4tUomZ/sl2BpacmFCxc0oiqfJ7ZSl/m0L9s30J4jbGxsjJmZGefOnVPGP727m56ezqJFi3j48CEDBgxg5cqV9O/fP99n3oiSJ9+CrVq1Kj4+Pqp8lEG3bt1IT09n1qxZ/Pbbb2zZsuW5TuyYmppy9+5doqOjuXv3bonqWy5tOcAffPABS5cuZd++fZw7d47PPvtMmbdMmTJERUXh5+dHfHw858+f5+zZs6/tsph4PnkK1szMjFmzZqmyWCHnuuiXX37JyZMnGTJkCPv27aNDhw5F3nLa2dlhb2+Pl5dXkb888ar6lsvd3Z0PP/yQmTNn0qtXL+7cuaORA+zl5UXnzp355JNPmDBhAm3btgVQdsdXrVpFZmYmvXv3ZtiwYTRo0ICpU6cW67oK3dBInNi4cSO9e/d+6TPEv//+u/JYvxc1derUF/4KYXp6unKsBzlbnObNm5eID2VBfatatSrBwcF5pm/SpAnffvvtcy3jyZMnGBoaKv8Ijh8/zgcffMBvv/0mOcAqp3H6cOjQoc991rKkefDgAT179mTatGk0btyY/fv388svvyiPFiypfatduzZdunTJM4+xsfFzL2fFihUkJiYyduxYUlNTmT9/Pi4uLlKspYBGwRZXsRbHMzZftI0KFSrg7e3N4sWLuXLlCnXq1GH58uU0adLkpfv0srT1raDHdTwvd3d3Fi5cyIABAzAwMMDR0VHj0RdCvXQWwlbQl/+LwtnZ+bkeISjEm0JSE4VQkVJ3HVaI0kwKVggVkYIVQkWkYIVQESlYIVREClYIFZGCFUJFpGCFUBEp2GKgi8zgLVu20L59+2JtU6hfqcglftP9+eef2NnZERkZSYMGDV53d4QOlYpcYiHeFKrNJT5//jwDBw6kSZMmODo6smXLFmXcgwcPmDFjBi1btqR58+ZMmjSJe/fuATmP6mjTpg0rV66kTZs22NjYMGfOHJKSkhg8eDCNGjWia9eunD59WlkXKysrli1bRufOnWnUqBGenp6kpKQU2Ld169bRvn17WrZsyeTJk4uUXJGUlMTQoUNp3Lgxffr04fz58xrjL126xIgRI2jcuDHt2rVT7p1dt24ddnZ2AHTt2pUFCxZofQ+Eeqk2l3jUqFE0a9aMyMhIxo0bx/Tp0zl79iwAM2fO5I8//uCbb77h+++/5/LlywQGBirz/v3339y8eZOvv/4aX19fNm7cSN++fRk2bBg//PAD5ubmTJs2TWN5v/32G99//z27d+8mKSmJefPm5duvTZs2ERISQnBwMN9++y23b9/G19dX6zp7e3tz//59Nm3ahLe3NwcOHFDGZWZm4uHhQc2aNdm3bx/BwcGsX7+enTt34uHhwaFDhwDYvn07U6ZMKdJ7INRJlbnEqampJCcn07FjR2rXrk3t2rUxMjKiXLlyAIwfPx5TU1Ml5qZPnz4aW2AjIyN8fX0xMDCgYcOGbNq0iWbNmtGzZ08ARo8ezcCBA3n06JEyj5eXF1WqVKFKlSpMnTqVUaNGsWDBgjw3mK9Zs4YpU6YoW73p06fTr18/goKC8sSN5rpy5QpHjx4lPDwcGxsbAMaOHcuSJUuUaVauXEm9evUoV64cNWvWpF27dpw+fZoePXoo6122bFklQlXbeyDUKc8nKDeXuCQXrYmJCV5eXowdO5ZOnTrh5OREt27dlJveq1evzueff85PP/3EnTt3yMjI4N1331Xm19PT07hZv3z58piamiqvcwvg8ePH+SY+WFtbk5mZSVJSEnXq1FGG37t3j+vXr+Pj48P06dOBnODv3Glr166d7/pcuXIFQ0NDjZvsny5uAwMDypYty+TJk4mJieHhw4c8fvyYQYMGFfgeaXsPhDqpNpfYx8eH3bt306pVKzZv3oyTkxOJiYkATJs2jZs3bxIWFkZMTEye3duXlRsbWtCtxJ9//jkRERFERESwa9cuoqKiqFGjRqFtGhkZFRjGlpaWhru7O9bW1uzdu5eYmJh842Sepuv3QLweqrwOGx8fT1BQEObm5nh6erJ161YqV65MeHg4kHNSa/DgwUqRaDsJVhRPF2dsbCyGhoZ5tliVKlWievXqXL9+HQsLC+WnWrVqBe4OQ87T9x49eqT8w3lWXFwct2/fZuTIkVSsWBFAY3c9v0LXxXsgXr98P0UlPZe4QoUKrF27Fn19fQYMGMDVq1dJTk5WsnUtLS3ZtGkT1atXJy4ujpUrV750XlJQUBC+vr7cu3ePgIAA+vTpk+/uspeXF0uWLOGdd96hefPmhIeHs3PnTnbt2lXgFtTc3Jz27dvj7+9PQEAAqampbNiwQRn/7rvvUqZMGZYtW0b37t3Zt28fP/30E/379wdy/lHo6+tz8OBBKlWqhJmZmU7eA/H6qTKX2MzMjLVr13Lw4EGcnZ3x8fHBy8uLbt26ARAYGMj9+/cZNmwY27ZtY/LkyZiYmJCenv7Cy2zZsiXjx4/H3d2devXqFZjCOGLECDw9PZk/fz7Ozs4cOnSIoKAgrdnDgYGBPHr0iA4dOuDl5aVkCQNUqVKF4OBgIiMj8fDwICkpiZEjRyq75mXKlMHLy4tly5Ypha6L90C8fqUyl7g4paamYmNjww8//ECLFi1euJ2YmBg++OCDfMedOHGiWJImRelX6nKJSypra+sCH8uRe1ZaCG1KXS5xSVWmTBksLCxedzeEykkusRAqIrnEQqiIKq/DCvGmkoIVQkWkYIVQESlYIVREClYIFZGCFUJFpGCFUBEpWCFURApWCBWRghVCRaRghVARKVghVOT/AJYAL5FvTl4iAAAAAElFTkSuQmCC)\n",
        "\n",
        "Burada Roboflow'a bağlanarak dataset indiriyor. Drive' kendimizde yükleyip dataset çekebiliriz. Bazı datasetlerin boyutu çok fazla olabiliyor. En mantıklısı, bir daha kullanılmayacaksa kendi linkinden indirmek, kullanılacaksa Google Drive(max: 15Gb)"
      ],
      "metadata": {
        "id": "kN9bxfbvA8OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"JCY9UG4yzFxIWXu1FOCH\")\n",
        "project = rf.workspace(\"plantsegment\").project(\"semseg-zz7by\")\n",
        "dataset = project.version(1).download(\"png-mask-semantic\")"
      ],
      "metadata": {
        "id": "2Nc042Oy1Ehr",
        "outputId": "41012f8f-23c1-4fdd-ac21-0490ec740214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in semseg-1 to png-mask-semantic: 100% [91219037 / 91219037] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to semseg-1 in png-mask-semantic:: 100%|██████████| 902/902 [00:00<00:00, 1017.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p4xQlUded1rh",
        "outputId": "745e3260-1e28-4e26-f2e9-9c63f5eb05fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Load to Segnet"
      ],
      "metadata": {
        "id": "g-G6N4P3Bxgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_dataset = SemanticSegmentationDataset(\"./Balloons-13/train/\", feature_extractor)\n",
        "\n",
        "Örnekte Balloons-13 dosya adıdıdr. Değiştirilmesi gerekir.\n"
      ],
      "metadata": {
        "id": "31BvR5rlB9lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class SemanticSegmentationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, feature_extractor):\n",
        "        self.root_dir = root_dir\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.classes_csv_file = os.path.join(self.root_dir, \"_classes.csv\")\n",
        "        with open(self.classes_csv_file, 'r') as fid:\n",
        "            data = [l.split(',') for i,l in enumerate(fid) if i !=0]\n",
        "        self.id2label = {x[0]:x[1] for x in data}\n",
        "        \n",
        "        image_file_names = [f for f in os.listdir(self.root_dir) if '.jpg' in f]\n",
        "        mask_file_names = [f for f in os.listdir(self.root_dir) if '.png' in f]\n",
        "        \n",
        "        self.images = sorted(image_file_names)\n",
        "        self.masks = sorted(mask_file_names)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        image = Image.open(os.path.join(self.root_dir, self.images[idx]))\n",
        "        segmentation_map = Image.open(os.path.join(self.root_dir, self.masks[idx]))\n",
        "\n",
        "        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n",
        "\n",
        "        for k,v in encoded_inputs.items():\n",
        "          encoded_inputs[k].squeeze_()\n",
        "\n",
        "        return encoded_inputs"
      ],
      "metadata": {
        "id": "V5Q_HYzn3ZJ2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import SegformerFeatureExtractor\n",
        "\n",
        "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "feature_extractor.reduce_labels = False\n",
        "feature_extractor.size = 128\n",
        "\n",
        "train_dataset = SemanticSegmentationDataset(\"./semseg-1/train/\", feature_extractor)\n",
        "val_dataset = SemanticSegmentationDataset(\"./semseg-1/valid/\", feature_extractor)\n",
        "test_dataset = SemanticSegmentationDataset(\"./semseg-1/test/\", feature_extractor)\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=3, prefetch_factor=8)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=3, prefetch_factor=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=3, prefetch_factor=8)"
      ],
      "metadata": {
        "id": "Kz12Hitt5cpG",
        "outputId": "60374cb7-36d8-437a-f537-d6e6cfba9847",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### İşlemler"
      ],
      "metadata": {
        "id": "6alLfF8UCPyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dokunma"
      ],
      "metadata": {
        "id": "DTL0Yoj5CS6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from PIL import Image\n",
        "from transformers import SegformerForSemanticSegmentation\n",
        "from datasets import load_metric\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class SegformerFinetuner(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
        "        super(SegformerFinetuner, self).__init__()\n",
        "        self.id2label = id2label\n",
        "        self.metrics_interval = metrics_interval\n",
        "        self.train_dl = train_dataloader\n",
        "        self.val_dl = val_dataloader\n",
        "        self.test_dl = test_dataloader\n",
        "        \n",
        "        self.num_classes = len(id2label.keys())\n",
        "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
        "        \n",
        "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "            \"nvidia/segformer-b0-finetuned-ade-512-512\", \n",
        "            return_dict=False, \n",
        "            num_labels=self.num_classes,\n",
        "            id2label=self.id2label,\n",
        "            label2id=self.label2id,\n",
        "            ignore_mismatched_sizes=True,\n",
        "        )\n",
        "        \n",
        "        self.train_mean_iou = load_metric(\"mean_iou\")\n",
        "        self.val_mean_iou = load_metric(\"mean_iou\")\n",
        "        self.test_mean_iou = load_metric(\"mean_iou\")\n",
        "        \n",
        "    def forward(self, images, masks):\n",
        "        outputs = self.model(pixel_values=images, labels=masks)\n",
        "        return(outputs)\n",
        "    \n",
        "    def training_step(self, batch, batch_nb):\n",
        "        \n",
        "        images, masks = batch['pixel_values'], batch['labels']\n",
        "        \n",
        "        outputs = self(images, masks)\n",
        "        \n",
        "        loss, logits = outputs[0], outputs[1]\n",
        "        \n",
        "        upsampled_logits = nn.functional.interpolate(\n",
        "            logits, \n",
        "            size=masks.shape[-2:], \n",
        "            mode=\"bilinear\", \n",
        "            align_corners=False\n",
        "        )\n",
        "\n",
        "        predicted = upsampled_logits.argmax(dim=1)\n",
        "\n",
        "        self.train_mean_iou.add_batch(\n",
        "            predictions=predicted.detach().cpu().numpy(), \n",
        "            references=masks.detach().cpu().numpy()\n",
        "        )\n",
        "        if batch_nb % self.metrics_interval == 0:\n",
        "\n",
        "            metrics = self.train_mean_iou.compute(\n",
        "                num_labels=self.num_classes, \n",
        "                ignore_index=255, \n",
        "                reduce_labels=False,\n",
        "            )\n",
        "            \n",
        "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
        "            \n",
        "            for k,v in metrics.items():\n",
        "                self.log(k,v)\n",
        "            \n",
        "            return(metrics)\n",
        "        else:\n",
        "            return({'loss': loss})\n",
        "    \n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        \n",
        "        images, masks = batch['pixel_values'], batch['labels']\n",
        "        \n",
        "        outputs = self(images, masks)\n",
        "        \n",
        "        loss, logits = outputs[0], outputs[1]\n",
        "        \n",
        "        upsampled_logits = nn.functional.interpolate(\n",
        "            logits, \n",
        "            size=masks.shape[-2:], \n",
        "            mode=\"bilinear\", \n",
        "            align_corners=False\n",
        "        )\n",
        "        \n",
        "        predicted = upsampled_logits.argmax(dim=1)\n",
        "        \n",
        "        self.val_mean_iou.add_batch(\n",
        "            predictions=predicted.detach().cpu().numpy(), \n",
        "            references=masks.detach().cpu().numpy()\n",
        "        )\n",
        "        \n",
        "        return({'val_loss': loss})\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        metrics = self.val_mean_iou.compute(\n",
        "              num_labels=self.num_classes, \n",
        "              ignore_index=255, \n",
        "              reduce_labels=False,\n",
        "          )\n",
        "        \n",
        "        avg_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        val_mean_iou = metrics[\"mean_iou\"]\n",
        "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
        "        \n",
        "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\":val_mean_iou, \"val_mean_accuracy\":val_mean_accuracy}\n",
        "        for k,v in metrics.items():\n",
        "            self.log(k,v)\n",
        "\n",
        "        return metrics\n",
        "    \n",
        "    def test_step(self, batch, batch_nb):\n",
        "        \n",
        "        images, masks = batch['pixel_values'], batch['labels']\n",
        "        \n",
        "        outputs = self(images, masks)\n",
        "        \n",
        "        loss, logits = outputs[0], outputs[1]\n",
        "        \n",
        "        upsampled_logits = nn.functional.interpolate(\n",
        "            logits, \n",
        "            size=masks.shape[-2:], \n",
        "            mode=\"bilinear\", \n",
        "            align_corners=False\n",
        "        )\n",
        "        \n",
        "        predicted = upsampled_logits.argmax(dim=1)\n",
        "        \n",
        "        self.test_mean_iou.add_batch(\n",
        "            predictions=predicted.detach().cpu().numpy(), \n",
        "            references=masks.detach().cpu().numpy()\n",
        "        )\n",
        "            \n",
        "        return({'test_loss': loss})\n",
        "    \n",
        "    def test_epoch_end(self, outputs):\n",
        "        metrics = self.test_mean_iou.compute(\n",
        "              num_labels=self.num_classes, \n",
        "              ignore_index=255, \n",
        "              reduce_labels=False,\n",
        "          )\n",
        "       \n",
        "        avg_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
        "        test_mean_iou = metrics[\"mean_iou\"]\n",
        "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
        "\n",
        "        metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\":test_mean_iou, \"test_mean_accuracy\":test_mean_accuracy}\n",
        "        \n",
        "        for k,v in metrics.items():\n",
        "            self.log(k,v)\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return self.train_dl\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return self.val_dl\n",
        "    \n",
        "    def test_dataloader(self):\n",
        "        return self.test_dl"
      ],
      "metadata": {
        "id": "i_75EQ0Z51mN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segformer_finetuner = SegformerFinetuner(\n",
        "    test_dataset.id2label, \n",
        "    train_dataloader=train_dataloader, \n",
        "    val_dataloader=val_dataloader, \n",
        "    test_dataloader=test_dataloader, \n",
        "    metrics_interval=10,\n",
        ")"
      ],
      "metadata": {
        "id": "gHm5Cpjn5_cj",
        "outputId": "07b85c6c-2f1c-4c9e-b5d4-d66be6ab8be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAIN"
      ],
      "metadata": {
        "id": "fyQi0KO-CYsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eğitim İşlemi\n"
      ],
      "metadata": {
        "id": "sAssvaMTCdy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\", \n",
        "    min_delta=0.00, \n",
        "    patience=3, \n",
        "    verbose=False, \n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1, \n",
        "    callbacks=[early_stop_callback, checkpoint_callback],\n",
        "    max_epochs=500,\n",
        "    val_check_interval=len(train_dataloader),\n",
        ")\n",
        "\n",
        "#trainer.fit(segformer_finetuner)"
      ],
      "metadata": {
        "id": "g_8Ie_k57JVI",
        "outputId": "263ad280-d139-42c4-d4bf-f199dec3b343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "BJ-bl4OGgzqV",
        "outputId": "10988a21-63eb-40ca-c69a-a0a6d8c5566c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LitModel(SegformerFinetuner):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(    train_dataset.id2label, \n",
        "    train_dataloader=train_dataloader, \n",
        "    val_dataloader=val_dataloader, \n",
        "    test_dataloader=test_dataloader, \n",
        "    metrics_interval=10,)\n",
        "\n",
        "x = segformer_finetuner = SegformerFinetuner(\n",
        "    train_dataset.id2label, \n",
        "    train_dataloader=train_dataloader, \n",
        "    val_dataloader=val_dataloader, \n",
        "    test_dataloader=test_dataloader, \n",
        "    metrics_interval=10,\n",
        ")\n",
        "model_test = LitModel.load_from_checkpoint('./sample_data/epoch=44-step=1935.ckpt')\n",
        "res = trainer.test(model_test)"
      ],
      "metadata": {
        "id": "xHSHh6Up-kNb",
        "outputId": "f9580fa7-3e5b-4e4a-b067-1013ac361323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "c1703c1642884cca95b4fc136f3ded25",
            "fe3a0a97070945a6abad7cb607eeee65",
            "ddf2c14cf98446bab04df3e99af275e6",
            "6d43083dbd1549bd997daeebd13dd5d4",
            "bcf52de12fd243008f387bef1d45018d",
            "00262a16d6ce4a6c88bf65e474c84f43",
            "282270417851478f8ae62899c7a3dbe5",
            "2e8a38064d284869a2ce24f0820abf77",
            "36e495249f09457693fdef364d3523d4",
            "7d5f3c8e1f7a4000b060278d0b655fe6",
            "16d1f53ff67349bcbed65956d19955d2"
          ]
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1703c1642884cca95b4fc136f3ded25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        test_loss           0.09652318805456161\n",
            "   test_mean_accuracy       0.9466056501279536\n",
            "      test_mean_iou         0.8954410684853993\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAMPLE VISUALISATION"
      ],
      "metadata": {
        "id": "2g8vm0yKCtb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_map = {\n",
        "    0:(0,0,0),\n",
        "    1:(255,0,0),\n",
        "}\n",
        "\n",
        "def prediction_to_vis(prediction):\n",
        "    vis_shape = prediction.shape + (3,)\n",
        "    vis = np.zeros(vis_shape)\n",
        "    for i,c in color_map.items():\n",
        "        vis[prediction == i] = color_map[i]\n",
        "    return Image.fromarray(vis.astype(np.uint8))\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    images, masks = batch['pixel_values'], batch['labels']\n",
        "    outputs = segformer_finetuner.model(images, masks)\n",
        "        \n",
        "    loss, logits = outputs[0], outputs[1]\n",
        "\n",
        "    upsampled_logits = nn.functional.interpolate(\n",
        "        logits, \n",
        "        size=masks.shape[-2:], \n",
        "        mode=\"bilinear\", \n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    predicted = upsampled_logits.argmax(dim=1).cpu().numpy()\n",
        "    masks = masks.cpu().numpy()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "f, axarr = plt.subplots(predicted.shape[0],2)\n",
        "for i in range(predicted.shape[0]):\n",
        "    axarr[i,0].imshow(prediction_to_vis(predicted[i,:,:]))\n",
        "    axarr[i,1].imshow(prediction_to_vis(masks[i,:,:]))"
      ],
      "metadata": {
        "id": "b_Dcq8Y7-q5S",
        "outputId": "22121f47-9928-4c6a-ba0e-e32bd5d7d29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f070d26f8457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegformer_finetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on a test image and overlay the mask on the original image\n",
        "test_idx = 0\n",
        "input_image_file = os.path.join(test_dataset.root_dir,test_dataset.images[test_idx])\n",
        "input_image = Image.open(input_image_file)\n",
        "test_batch = test_dataset[test_idx]\n",
        "images, masks = test_batch['pixel_values'], test_batch['labels']\n",
        "images = torch.unsqueeze(images, 0)\n",
        "masks = torch.unsqueeze(masks, 0)\n",
        "outputs = segformer_finetuner.model(images, masks)\n",
        "    \n",
        "loss, logits = outputs[0], outputs[1]\n",
        "\n",
        "upsampled_logits = nn.functional.interpolate(\n",
        "    logits, \n",
        "    size=masks.shape[-2:], \n",
        "    mode=\"bilinear\", \n",
        "    align_corners=False\n",
        ")\n",
        "predicted_mask = upsampled_logits.argmax(dim=1).cpu().numpy()\n",
        "mask = prediction_to_vis(np.squeeze(masks))\n",
        "mask = mask.resize(input_image.size)\n",
        "mask = mask.convert(\"RGBA\")\n",
        "input_image = input_image.convert(\"RGBA\")\n",
        "overlay_img = Image.blend(input_image, mask, 0.5)"
      ],
      "metadata": {
        "id": "oy3N50URu9A8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1703c1642884cca95b4fc136f3ded25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe3a0a97070945a6abad7cb607eeee65",
              "IPY_MODEL_ddf2c14cf98446bab04df3e99af275e6",
              "IPY_MODEL_6d43083dbd1549bd997daeebd13dd5d4"
            ],
            "layout": "IPY_MODEL_bcf52de12fd243008f387bef1d45018d"
          }
        },
        "fe3a0a97070945a6abad7cb607eeee65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00262a16d6ce4a6c88bf65e474c84f43",
            "placeholder": "​",
            "style": "IPY_MODEL_282270417851478f8ae62899c7a3dbe5",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "ddf2c14cf98446bab04df3e99af275e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8a38064d284869a2ce24f0820abf77",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36e495249f09457693fdef364d3523d4",
            "value": 5
          }
        },
        "6d43083dbd1549bd997daeebd13dd5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5f3c8e1f7a4000b060278d0b655fe6",
            "placeholder": "​",
            "style": "IPY_MODEL_16d1f53ff67349bcbed65956d19955d2",
            "value": " 5/5 [00:09&lt;00:00,  1.92s/it]"
          }
        },
        "bcf52de12fd243008f387bef1d45018d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "00262a16d6ce4a6c88bf65e474c84f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282270417851478f8ae62899c7a3dbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e8a38064d284869a2ce24f0820abf77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e495249f09457693fdef364d3523d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d5f3c8e1f7a4000b060278d0b655fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d1f53ff67349bcbed65956d19955d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}